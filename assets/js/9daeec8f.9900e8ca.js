"use strict";(self.webpackChunkwalnut_plan=self.webpackChunkwalnut_plan||[]).push([[1096],{2141:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>u,frontMatter:()=>n,metadata:()=>s,toc:()=>c});var a=i(4848),o=i(8453);const n={sidebar_position:1},r="How to Evaluate our Trials?",s={id:"projects/o1_replicate/exploration_journey/eval_trial",title:"How to Evaluate our Trials?",description:"In addition to testing accuracy scores using specific evaluation metrics on benchmarks, manually reviewing actual cases is a crucial step in evaluating data and models. Therefore, to provide a more intuitive way to evaluate the model\u2019s performance on specific problems, we build a visual data analysis platform using Streamlit. Specifically, our visualization platform includes the visualization of synthetic trees and their corresponding long thoughts as well as the output of the trained model. Furthermore, when visualizing results, we support detailed conditional filtering, such as filtering for correctly or incorrectly answered questions, or whether the output contains keywords indicating reflection or hesitation (e.g., \u201cwait\u201d). Additionally, we support comparison between different iterations of synthetic data and model outputs, which makes it highly intuitive and helps us easily validate whether the new round of data or models is effective.",source:"@site/docs/projects/o1_replicate/2_exploration_journey/08_eval_trial.md",sourceDirName:"projects/o1_replicate/2_exploration_journey",slug:"/projects/o1_replicate/exploration_journey/eval_trial",permalink:"/walnut-plan/docs/projects/o1_replicate/exploration_journey/eval_trial",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"How to Derive a Long Thought from a Reasoning Tree?",permalink:"/walnut-plan/docs/projects/o1_replicate/exploration_journey/tree2thought"},next:{title:"How to Train our Models?",permalink:"/walnut-plan/docs/projects/o1_replicate/exploration_journey/train"}},l={},c=[];function d(e){const t={em:"em",h1:"h1",header:"header",img:"img",p:"p",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.header,{children:(0,a.jsx)(t.h1,{id:"how-to-evaluate-our-trials",children:"How to Evaluate our Trials?"})}),"\n",(0,a.jsx)(t.h1,{id:"a-visualization-platform",children:"A Visualization Platform"}),"\n",(0,a.jsx)(t.p,{children:"In addition to testing accuracy scores using specific evaluation metrics on benchmarks, manually reviewing actual cases is a crucial step in evaluating data and models. Therefore, to provide a more intuitive way to evaluate the model\u2019s performance on specific problems, we build a visual data analysis platform using Streamlit. Specifically, our visualization platform includes the visualization of synthetic trees and their corresponding long thoughts as well as the output of the trained model. Furthermore, when visualizing results, we support detailed conditional filtering, such as filtering for correctly or incorrectly answered questions, or whether the output contains keywords indicating reflection or hesitation (e.g., \u201cwait\u201d). Additionally, we support comparison between different iterations of synthetic data and model outputs, which makes it highly intuitive and helps us easily validate whether the new round of data or models is effective."}),"\n",(0,a.jsxs)(t.table,{children:[(0,a.jsx)(t.thead,{children:(0,a.jsx)(t.tr,{children:(0,a.jsx)(t.th,{style:{textAlign:"center"},children:(0,a.jsx)(t.img,{src:i(1433).A+"",width:"1280",height:"707"})})})}),(0,a.jsx)(t.tbody,{children:(0,a.jsx)(t.tr,{children:(0,a.jsx)(t.td,{style:{textAlign:"center"},children:(0,a.jsx)(t.em,{children:"Visualizing the constructed search tree through an interactive data analysis platform."})})})})]})]})}function u(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},1433:(e,t,i)=>{i.d(t,{A:()=>a});const a=i.p+"assets/images/platform-17adf6de6033477d79dc19fbe5d06963.png"},8453:(e,t,i)=>{i.d(t,{R:()=>r,x:()=>s});var a=i(6540);const o={},n=a.createContext(o);function r(e){const t=a.useContext(n);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),a.createElement(n.Provider,{value:t},e.children)}}}]);